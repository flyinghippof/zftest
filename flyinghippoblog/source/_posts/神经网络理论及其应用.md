---
title: 神经网络理论及其应用
date: 2020-12-1
tags:
mathjax: true

---



在学校蹭的一个课，电子版没有，讲义复习（重新学）

这讲义是纸质的，老师竟然没给电子版，先搁置了，有充足的时间再学吧



<!-- more -->

# 第一章 神经网络概述

- 神经网络是由大量简单的基本元件--神经元相互连接而成的自适应非线性动态系统

- 麦卡洛克-皮特斯模型 (McCulloch-Pitts model )简称MP模型一种神经元网络模型.

  该模型的主要目的是完成对神经元状态的描述.通过对大脑的分析，人们发现，从信息处理的功能看，神经元由以下特点:
  1.多输入单输出.
  2.突触(传递神经冲动的地方)兼有兴奋和抑制两种性能.
  3.能时间加权和空间加权.
  4.可产生脉冲.
  5.脉冲进行传递
  6.非线性(有值).

- $ net′_j(t)=\sum _{i=0}^nω_{ij}χ_i(t)$   $y_j=f(net_j)$

- Rumelhart的PDP模型（英文全称是parallel distributed processing，中文称之为并行分布模型。）：有八个方面：

  1. 处理单元个数
  2. 单元集合的激活
  3. 各单元的输出函数。将激活状态映射为各单元的输出。输出的函数可以有不同的规律，如恒同函数，阈值函数、概率统计函数。
  4. 单元互联模式
  5. 传播规则
  6. 激活规则
  7. 学习规律
  8. 系统工作环境

- 通常只考虑三方面：

  1. 神经元功能函数
  2. 神经元之间的连接形式
  3. 学习规则

- **神经元功能函数**是输入信号到输出信号的映射。其综合了净输入、激活规则函数和输出函数。其可以划分为三种类型：简单的映射关系、动态系统方程和概率统计模型。

  - 简单的映射关系：不考虑神经元的滞后效应，各神经元构成的输出和输入矢量符合某种映射关系
  - 动态系统方程：反映了神经元输出和输入之间的延时作用。通常用差分方程或微分方程表示。
  - 概率统计模型：网络在某一时刻的状态无意义，而是研究状态的统计规律

- 神经元功能函数示例：简单线性模型、线性阈值单元、sigmoid函数模型、多项式阈值函数模型

- **神经元之间的连接形式**：

  1. 前向网络：第i层的神经元只接受第i-1层神经元输出的信号，各神经元之间没有反馈，可以用有向无环图来表示。每个计算节点可有任意个输入，但只有一个输出。
  2. 反馈网络：每个节点同时接受外加输入和其他各节点的反馈输入，每个节点也都直接向外部输出。

- **学习（训练）：**

  1. 监督学习：常见的监督学习有Hebb规则和Widrow-Hoff规则。

  2. 无监督学习：

     学习过程为：给系统提供动态输入信号以使各单元以某种方式竞争，“获胜者”神经元本身或其邻域得到增强，其他神经元进一步受到抑制，从而将信号分成有用的多个区域。

     学习阶段和应用阶段融为一体，不可分割。



- 人工神经网络的基本功能：
  1. 联想记忆：通过部分（残缺）线索信息存取或唤起相应的记忆。
     1. 自联想（auto-AM）：去除噪声或干扰使信号复原
     2. 异联想（Hetero-AM）：在有噪声的情况下映射成功
  2. 分类
  3. 优化计算（优化决策）





# 第二章 前向多层神经网络

## 2.1 引言

- 前向多层神经网络的输出和输入之间是一种映射关系，其设计神经网络的两项基本功能：联想与分类。
- 对学习训练的几项要求：
  - 准确性：按照某种准则，使实际输出与理想输出之间的误差最小
  - 自适应性：不受人为干预
  - 收敛性与收敛速度：解唯一、速度快
  - 必须规定是有监督还是无监督
  - 可推广性：泛化
- 静态神经元模型：输入向量与权重向量相乘，再减去（或加上）b，再通过一个变换函数（单调非降函数）进行输出。
- 变换函数有：线性函数、硬限幅函数和sigmoid函数等。

## 2.2 采用硬限幅函数时单个神经元的分类功能























